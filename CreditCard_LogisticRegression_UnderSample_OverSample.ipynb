{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGboost classification_LH.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xslittlemaggie/Deep-Learning-Machine-Learning-Projects/blob/master/CreditCard_LogisticRegression_UnderSample_OverSample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppKnMl7-bMxW",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A9mCY8ebP7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, roc_curve, auc\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ4sRQH_cIyp",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLbXJ9qO1aHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a20f1fce-f8a8-4a0f-ef63-3a0a718cd0bd"
      },
      "source": [
        "# need to upload data from local manually\n",
        "data = pd.read_csv('/content/creditcard.csv')\n",
        "data.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3f1FWgvEjD",
        "colab_type": "code",
        "outputId": "a92f4c85-02bc-400f-f8b1-2c88d4d139d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KaTXg5HvtYg",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8_oZgYevwLs",
        "colab_type": "text"
      },
      "source": [
        "This section will include feature preprocessing, such as feature combinaiton, convertion, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZH4GFFFFAIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "cead681b-5bed-4492-efe7-37baa06ecbfa"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eenTUuhCFJoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_classes = pd.value_counts(data[\"Amount\"], sort = True).sort_index()\n",
        "#count_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz4ccUliFR9t",
        "colab_type": "text"
      },
      "source": [
        "1. The feature **Time** seems not to be related to the target varaible **Class**, will drop \"Time\".\n",
        "2. The range of of the feature **Amount** vary a lot from 0 to 25691,  need to standardize it.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41yX6dTtBN1W",
        "colab_type": "text"
      },
      "source": [
        "### 1.Standardize feature \"Amount\" and drop \"Time\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si7jC38q-GiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "cad408be-9dc0-4d44-a891-c9980af70e36"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "data[\"normAmount\"] = StandardScaler().fit_transform(data[[\"Amount\"]]).reshape(-1, 1)\n",
        "data = data.drop([\"Amount\", \"Time\"], axis = 1)\n",
        "data.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>normAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.342475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>1.160686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3  ...       V28  Class  normAmount\n",
              "0 -1.359807 -0.072781  2.536347  ... -0.021053      0    0.244964\n",
              "1  1.191857  0.266151  0.166480  ...  0.014724      0   -0.342475\n",
              "2 -1.358354 -1.340163  1.773209  ... -0.059752      0    1.160686\n",
              "3 -0.966272 -0.185226  1.792993  ...  0.061458      0    0.140534\n",
              "4 -1.158233  0.877737  1.548718  ...  0.215153      0   -0.073403\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgdvhRKf_Ec",
        "colab_type": "text"
      },
      "source": [
        "### 2. About the target variable, Class (0 & 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwU9VaqOcNd7",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1 check the rows when target variable is null and drop the rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR8ZSiiZcIKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(data.isnull().sum())\n",
        "data = data.dropna(axis=0, subset=['Class'])\n",
        "#print(data.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gUciZSdcXoJ",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 check the distribution of the target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_lBOpVngm8E",
        "colab_type": "text"
      },
      "source": [
        "The sample size of the target variable is imbalance. \n",
        "\n",
        "Next, I will run the models based on different conditions to compare the performances.\n",
        "\n",
        "1. Run the model with the original dataset (imbalanced dataset)\n",
        "\n",
        "2. Use under-sampling (下采样) to balance the sample sizes between the two classes, and fit the model, and get the performance.\n",
        "\n",
        "3. Use over-sampling (过采样) to balance the sample size betwee the two classes, and fit the model, and get the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwFT_L0rf1un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "33c543b8-edb4-47b8-e84a-555055b7f9b2"
      },
      "source": [
        "count_classes = pd.value_counts(data[\"Class\"], sort = True).sort_index()\n",
        "print(count_classes)\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"Fraud class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDBtJUneGjSSpO8NGktTd/wfPdsKHs6aZdQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faS93sEgcMl2",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt8MUGF30Wl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "dbe160fb-f7b4-4ded-d1de-30707c7bb579"
      },
      "source": [
        "X = data.drop([\"Class\"], axis = 1)\n",
        "Y = data[\"Class\"]\n",
        "# get the train, test datasets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(\"Number of transactions train dataset:\", len(x_train))\n",
        "print(\"Number of transactions test dataset:\", len(x_test))\n",
        "print(\"The total number of transactions:\", len(X))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of transactions train dataset: 227845\n",
            "Number of transactions test dataset: 56962\n",
            "The total number of transactions: 284807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVbQrenbaoHC",
        "colab_type": "text"
      },
      "source": [
        "### Model 1. Model with the imbalanced original dataset (class 0 : class 1 = 228:1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySuIR2k8ofLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfM-hk8KueKl",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Model fitting for the imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RdwgmOLcDXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_Kfold_score(x_train, y_train):\n",
        "  kf = KFold(n_splits = 5, shuffle = False)\n",
        "\n",
        "  # different C parameters\n",
        "  c_params_range = [0.01, 0.1, 1, 10, 100]\n",
        "  results_table = pd.DataFrame(index = range(len(c_params_range), 2), columns = [\"C_parameter\", \"Mean_recall_score\"])\n",
        "  results_table[\"C_parameter\"] = c_params_range\n",
        "\n",
        "  # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
        "  i = 0\n",
        "  for c_param in c_params_range:\n",
        "    print(\"-\" * 20)\n",
        "    print(\"C_Parameter:\", c_param)\n",
        "    print(\"-\" * 20)\n",
        "    print()\n",
        "\n",
        "    recall_accs = []\n",
        "    for iteration, indices in enumerate(kf.split(x_train, y_train), start = 1):\n",
        "      # call the logistic regression model with a certain C Parameter\n",
        "      lr = LogisticRegression(C = c_param, penalty = \"l1\")\n",
        "      # Use the training data to fit the model. In this case, I will use the portion of the fold to train the model\n",
        "      # with indices[0], I predict on the portion assigned as the \"test cross validation\" \n",
        "      lr.fit(x_train.iloc[indices[0], :], y_train.iloc[indices[0]])\n",
        "      # predict values using the test indices in the training data\n",
        "      y_pred = lr.predict(x_train.iloc[indices[1]])                                  \n",
        "\n",
        "      # calculate the recall score and append it to a list for recall scores representing the current \n",
        "      recall_acc = recall_score(y_train.iloc[indices[1]], y_pred)\n",
        "      recall_accs.append(recall_acc)\n",
        "      print(\"Iteration:\", iteration, \", recall score = \", recall_acc)\n",
        "\n",
        "    # the mean value of those recall scores is the metric we want to save and get hold of\n",
        "    results_table.loc[i, \"Mean_recall_score\"] = np.mean(recall_accs)\n",
        "    i += 1\n",
        "    print()\n",
        "    print(\"Mean recall score\", np.mean(recall_accs))\n",
        "    print()\n",
        "\n",
        "  best_c = results_table.loc[results_table[\"Mean_recall_score\"].astype(float).idxmax()][\"C_parameter\"]\n",
        "\n",
        "  # finally, we can check which C parameter is the best among the chosen\n",
        "\n",
        "  print(\"*\" * 20)\n",
        "  print(\"Best model to choose from cross validation is with C parameter = \", best_c)\n",
        "  print(\"*\" * 20)\n",
        "  return best_c  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMm_XNbyqH8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f803d64f-4483-4093-faae-8651a2e73405"
      },
      "source": [
        "best_c = print_Kfold_score(x_train, y_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "C_Parameter: 0.01\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.5066666666666667\n",
            "Iteration: 2 , recall score =  0.575\n",
            "Iteration: 3 , recall score =  0.6\n",
            "Iteration: 4 , recall score =  0.6233766233766234\n",
            "Iteration: 5 , recall score =  0.4523809523809524\n",
            "\n",
            "Mean recall score 0.5514848484848486\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 0.1\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.5466666666666666\n",
            "Iteration: 2 , recall score =  0.6125\n",
            "Iteration: 3 , recall score =  0.64\n",
            "Iteration: 4 , recall score =  0.6623376623376623\n",
            "Iteration: 5 , recall score =  0.4880952380952381\n",
            "\n",
            "Mean recall score 0.5899199134199135\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 1\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.5333333333333333\n",
            "Iteration: 2 , recall score =  0.625\n",
            "Iteration: 3 , recall score =  0.6533333333333333\n",
            "Iteration: 4 , recall score =  0.6753246753246753\n",
            "Iteration: 5 , recall score =  0.5476190476190477\n",
            "\n",
            "Mean recall score 0.6069220779220779\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 10\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.5466666666666666\n",
            "Iteration: 2 , recall score =  0.625\n",
            "Iteration: 3 , recall score =  0.6666666666666666\n",
            "Iteration: 4 , recall score =  0.6753246753246753\n",
            "Iteration: 5 , recall score =  0.5476190476190477\n",
            "\n",
            "Mean recall score 0.6122554112554113\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 100\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.5466666666666666\n",
            "Iteration: 2 , recall score =  0.625\n",
            "Iteration: 3 , recall score =  0.6666666666666666\n",
            "Iteration: 4 , recall score =  0.6753246753246753\n",
            "Iteration: 5 , recall score =  0.5476190476190477\n",
            "\n",
            "Mean recall score 0.6122554112554113\n",
            "\n",
            "********************\n",
            "Best model to choose from cross validation is with C parameter =  10.0\n",
            "********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5D9lOgupaax",
        "colab_type": "text"
      },
      "source": [
        "From the results above, the best performance (mean recall score) is about 0.62 when C_parameter = 10.\n",
        "\n",
        "This performance is not high enough to be a good model.\n",
        "\n",
        "Next, I will use the under_sampling method to balance the sample sizes and analyze the performance (mean recall score) again.\n",
        "\n",
        "**Note**: could also compare the accuracy. But the accuracy is usually not a good indicator of model performance, especially when the dataset is imbalanced. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJDn5lo7uVWG",
        "colab_type": "text"
      },
      "source": [
        "#### 2. More analysis about recall score, and accuracy\n",
        "\n",
        "Recall_score = TP / (TP + FN)\n",
        "\n",
        "Accuracy = (TP + TN) / len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CwmEHofv5CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "21267cae-a70a-460a-83a0-bef4c3e31912"
      },
      "source": [
        "lr = LogisticRegression(C = best_c, penalty = \"l1\")\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "# compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "np.set_printoptions(precision = 2)\n",
        "\n",
        "print(\"Recall score in the testing dataset:\", cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
        "print(\"Accuracy in the testing dataset:\", (cnf_matrix[0, 0] + cnf_matrix[1, 1])/(len(x_test)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score in the testing dataset: 0.6435643564356436\n",
            "Accuracy in the testing dataset: 0.9992099996488887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWJYm2x6AbPN",
        "colab_type": "text"
      },
      "source": [
        "Even though the accuracy is very high, the recall score is low. This is because the dataset is very imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MlPYo52uy31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, title = \"Confusion matrix\", cmap = plt.cm.Wistia):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix\n",
        "  \"\"\"\n",
        "  plt.figure(figsize = (6, 6))\n",
        "  plt.imshow(cm, interpolation = \"nearest\", cmap = plt.cm.Wistia) # plt.cm.Blues\n",
        "  plt.title(\"Confusion Matrix\", size = 14)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2) # len(classes)\n",
        "  plt.xticks(tick_marks,rotation = 0)\n",
        "  plt.yticks(tick_marks,rotation = 0)\n",
        "  plt.xlabel('Predicted class', size = 12)\n",
        "  plt.ylabel('True class', size = 12)\n",
        "  s = [['TN','FP'], ['FN', 'TP']]\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      plt.text(j, i, str(s[i][j]+ \"=\" + str(cm[i][j]) ), size = 10)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYVyhPoU7MMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "b1dab66a-7ba5-4289-d464-ffb5e86898cf"
      },
      "source": [
        "plot_confusion_matrix(cnf_matrix, title = \"Confusion matrix\", cmap = plt.cm.Wistia)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFcCAYAAADBO2nrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y21fYtIvAFaA",
        "colab_type": "text"
      },
      "source": [
        "### Model 2. Model with under_sampling to balance the dataset \n",
        "\n",
        "#### 1. 下采样 (同样少）\n",
        "To drop the class with more samples to make the sample size equal to that of the class with less samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "243xMm2XEsoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "872aa842-9251-41fb-8105-701cd55b2bfd"
      },
      "source": [
        "# get the indices for the data points in the minority class\n",
        "number_records_fraud = len(y_train[y_train == 1])\n",
        "fraud_indices = np.array(y_train[y_train == 1].index)\n",
        "\n",
        "# get the indices of the normal classes\n",
        "normal_indices = y_train[y_train == 0].index\n",
        "\n",
        "# out of the indices of normal classes, randomly select \"X\" number (number_records_fraud)\n",
        "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
        "random_normal_indices = np.array(random_normal_indices)\n",
        "\n",
        "# Appending the 2 indices\n",
        "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
        "\n",
        "# Under sample dataset\n",
        "\n",
        "under_sample_data = data.iloc[under_sample_indices, :]\n",
        "\n",
        "us_x = under_sample_data.iloc[:, under_sample_data.columns != \"Class\"]\n",
        "us_y = under_sample_data.iloc[:, under_sample_data.columns == \"Class\"]\n",
        "\n",
        "# Showing ratio\n",
        "print(\"Percentage of normal transactions:\", len(us_y[us_y[\"Class\"] == 0])/len(us_y))\n",
        "print(\"Percentage of unnormal transactions:\", len(us_y[us_y[\"Class\"] == 1])/len(us_y))\n",
        "print(\"Total number of transactions in resampled data:\", len(us_y))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of normal transactions: 0.5\n",
            "Percentage of unnormal transactions: 0.5\n",
            "Total number of transactions in resampled data: 782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ikDijHsVPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5e510ab-301a-4c8f-8ced-a52e2de5ee24"
      },
      "source": [
        "best_c = print_Kfold_score(us_x, us_y)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "C_Parameter: 0.01\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.8726114649681529\n",
            "Iteration: 2 , recall score =  0.8853503184713376\n",
            "Iteration: 3 , recall score =  0.961038961038961\n",
            "Iteration: 4 , recall score =  0.0\n",
            "Iteration: 5 , recall score =  0.0\n",
            "\n",
            "Mean recall score 0.5438001488956903\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 0.1\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.8598726114649682\n",
            "Iteration: 2 , recall score =  0.8853503184713376\n",
            "Iteration: 3 , recall score =  0.922077922077922\n",
            "Iteration: 4 , recall score =  0.0\n",
            "Iteration: 5 , recall score =  0.0\n",
            "\n",
            "Mean recall score 0.5334601704028457\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 1\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.8789808917197452\n",
            "Iteration: 2 , recall score =  0.8980891719745223\n",
            "Iteration: 3 , recall score =  0.935064935064935\n",
            "Iteration: 4 , recall score =  0.0\n",
            "Iteration: 5 , recall score =  0.0\n",
            "\n",
            "Mean recall score 0.5424269997518405\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 10\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.8789808917197452\n",
            "Iteration: 2 , recall score =  0.8980891719745223\n",
            "Iteration: 3 , recall score =  0.935064935064935\n",
            "Iteration: 4 , recall score =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.0\n",
            "\n",
            "Mean recall score 0.5424269997518405\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 100\n",
            "--------------------\n",
            "\n",
            "Iteration: 1 , recall score =  0.8726114649681529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.8980891719745223\n",
            "Iteration: 3 , recall score =  0.935064935064935\n",
            "Iteration: 4 , recall score =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.0\n",
            "\n",
            "Mean recall score 0.541153114401522\n",
            "\n",
            "********************\n",
            "Best model to choose from cross validation is with C parameter =  0.01\n",
            "********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "558CHVBsBdrH",
        "colab_type": "text"
      },
      "source": [
        "With the under_sampling, the sample size becomes very small, 984 in total. And the recall_scores are very unstable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfqapbzkBWK-",
        "colab_type": "text"
      },
      "source": [
        "#### 2. More analysis about recall score, and accuracy\n",
        "\n",
        "Recall_score = TP / (TP + FN)\n",
        "\n",
        "Accuracy = (TP + TN) / len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cafa639e-a823-4299-a170-f81ec214ae01",
        "id": "xFJFNf3hBR7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "lr = LogisticRegression(C = best_c, penalty = \"l1\")\n",
        "lr.fit(us_x, us_y)\n",
        "y_pred = lr.predict(x_test)\n",
        "# compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "np.set_printoptions(precision = 2)\n",
        "\n",
        "print(\"Recall score in the testing dataset:\", cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
        "print(\"Accuracy in the testing dataset:\", (cnf_matrix[0, 0] + cnf_matrix[1, 1])/(len(x_test)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score in the testing dataset: 0.9306930693069307\n",
            "Accuracy in the testing dataset: 0.9405919735964328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DofxX0b9CaRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "9d5dfa7a-e08d-4ab6-d73f-a7bd58fcc0d4"
      },
      "source": [
        "plot_confusion_matrix(cnf_matrix, title = \"Confusion matrix\", cmap = plt.cm.Wistia)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFcCAYAAADBO2nrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mqo0gtEtBR7b"
      },
      "source": [
        "Compred to the original dataset, from the results above, the recall score increases, but the accuracy decrease. \n",
        "\n",
        "In addition, to increase the recall score, the FP increases significantly, which would make great impact practically.\n",
        "\n",
        "For example, practically,  for the predicted unnormal cases, the bank would investigate the unnormal cases one by one. \n",
        "\n",
        "\n",
        "Thus, even though the FP will not impact our recall score much, it will impack the practical conditions a lot. \n",
        "\n",
        "\n",
        "The performance of the under_sampling is not good. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBayOCFMABX8",
        "colab_type": "text"
      },
      "source": [
        "### Model 3. Model with over_sampling to balance the dataset (SMOTE)\n",
        "\n",
        "#### 1. 过采样 (同样多)\n",
        "\n",
        "To resample the class with less samples to make the sample size equal to that of the class with more smaples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reu3omllQLnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaYuG1DgQqh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample = SMOTE(random_state = 0)\n",
        "os_x, os_y = oversample.fit_sample(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqfU-rhiRp6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f923a1aa-4048-465a-c29a-e6fbbee38833"
      },
      "source": [
        "print(\"The sample size when Class = 1:\", len(os_y[os_y == 1]))\n",
        "print(\"The sample size when Class = 0:\", len(os_y[os_y == 0]))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sample size when Class = 1: 227454\n",
            "The sample size when Class = 0: 227454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXZIx3JuGUTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dce44019-e9f4-4eef-b5a5-6143e3b3455f"
      },
      "source": [
        "os_x = pd.DataFrame(os_x)\n",
        "os_y = pd.DataFrame(os_y)\n",
        "\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "best_c = print_Kfold_score(os_x, os_y)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "C_Parameter: 0.01\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.9161290322580645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.9144736842105263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 3 , recall score =  0.9098152041606727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4 , recall score =  0.8918565414756927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.8927248546399797\n",
            "\n",
            "Mean recall score 0.9049998633489873\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 0.1\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.9161290322580645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.9144736842105263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 3 , recall score =  0.9111873409317252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4 , recall score =  0.8941537244039964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.8944394983567998\n",
            "\n",
            "Mean recall score 0.9060766560322225\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 1\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.9161290322580645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.9144736842105263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 3 , recall score =  0.911297997122939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4 , recall score =  0.8943955331332916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.8950989767094228\n",
            "\n",
            "Mean recall score 0.9062790446868488\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 10\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.9161290322580645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.9144736842105263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 3 , recall score =  0.9113201283611818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4 , recall score =  0.8944175157450457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.895131950627054\n",
            "\n",
            "Mean recall score 0.9062944622403745\n",
            "\n",
            "--------------------\n",
            "C_Parameter: 100\n",
            "--------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1 , recall score =  0.9161290322580645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2 , recall score =  0.9144736842105263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 3 , recall score =  0.9113201283611818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4 , recall score =  0.8942856200745211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 5 , recall score =  0.8951539332388081\n",
            "\n",
            "Mean recall score 0.9062724796286205\n",
            "\n",
            "********************\n",
            "Best model to choose from cross validation is with C parameter =  10.0\n",
            "********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4l68uQuTbqj",
        "colab_type": "text"
      },
      "source": [
        "#### 2. More analysis about recall score, and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmR9cHrTlJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "dad3a643-14fa-4976-f814-dd3ca3293d0c"
      },
      "source": [
        "lr = LogisticRegression(C = best_c, penalty = \"l1\")\n",
        "lr.fit(os_x, os_y)\n",
        "y_pred = lr.predict(x_test)\n",
        "# compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "np.set_printoptions(precision = 2)\n",
        "\n",
        "print(\"Recall score in the testing dataset:\", cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
        "print(\"Accuracy in the testing dataset:\", (cnf_matrix[0, 0] + cnf_matrix[1, 1])/(len(x_test)))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Recall score in the testing dataset: 0.9405940594059405\n",
            "Accuracy in the testing dataset: 0.975088655594958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrM8Uzy3Y8bQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "76cdad46-c0cb-4cc0-ce50-fe6ce51f0ca6"
      },
      "source": [
        "plot_confusion_matrix(cnf_matrix, title = \"cnf_matrix\", cmap = plt.cm.Wistia)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFcCAYAAADBO2nrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-u_7c-TXNH7",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Comparison of the three models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olXAwXNzXW-H",
        "colab_type": "text"
      },
      "source": [
        "Analysis based on the three confusions matrixs:\n",
        "\n",
        "1. 对于原始的不平衡数据，accuracy 可能很高， recall_score (0.62) 很低， 对于我们想要identify 出的正例测出的很少\n",
        "2. 下采样， recall_score (0.94),  代价是把很多负例探测成正例 （FP = 1756）,  这在实际情况中会增加我们很多工作量，比如银行将不是fraud的探测成fraud，银行需要一个一个调查.\n",
        "\n",
        "3. 过采样， recall_score (0.92), 虽然recall_score 减少了一点点， 但是(FP = 1041), 工作了减少了很多"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRf16eaQGkw4",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: More analysis about Logistic Regression parameter (a) 阈值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I6gD5N8H-4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_a(cm, i, title = \"Confusion matrix\", cmap = plt.cm.Wistia ): # plt.cm.Wistia\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix\n",
        "  \"\"\"\n",
        "  #plt.figure(figsize = (3, 3))\n",
        "  plt.imshow(cm, interpolation = \"nearest\", cmap = cmap) # plt.cm.Blues\n",
        "  plt.title(\"Threshold >=\" + str(i), size = 12)\n",
        "  #plt.colorbar()\n",
        "  tick_marks = np.arange(2) # len(classes)\n",
        "  plt.xticks(tick_marks,rotation = 0)\n",
        "  plt.yticks(tick_marks,rotation = 0)\n",
        "  if i in [0.8]:\n",
        "    plt.xlabel('Predicted', size = 12)\n",
        "  if i in [0.4]:\n",
        "    plt.ylabel('True', size = 12)\n",
        "  s = [['TN','FP'], ['FN', 'TP']]\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      plt.text(j, i, str(cm[i][j]), size = 10) # str(s[i][j]+ \" = \" + "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRcPYwsdGzbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "95fbed24-7cb4-4ca8-feb8-c1ab46644c4d"
      },
      "source": [
        "lr = LogisticRegression(C = best_c, penalty = \"l1\")\n",
        "lr.fit(os_x, os_y)\n",
        "y_pred_proba = lr.predict_proba(x_test)\n",
        "\n",
        "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "plt.figure(figsize = (12, 12))\n",
        "\n",
        "j = 1\n",
        "for i in thresholds:\n",
        "  print(\"Threshold = {}, Recall score = {:.4f}\".format(i, cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1])))\n",
        "  y_test_predictions_high_recall = y_pred_proba[:, 1] >= i\n",
        "  plt.subplot(3, 3, j)\n",
        "  j += 1\n",
        "  # compute confusion matrix\n",
        "  cnf_matrix = confusion_matrix(y_test, y_test_predictions_high_recall)\n",
        "  np.set_printoptions(precision = 2)\n",
        "  plot_confusion_a(cnf_matrix, i, title = \"Confusion matrix\", cmap = plt.cm.Wistia)\n",
        "  \n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Threshold = 0.1, Recall score = 0.9406\n",
            "Threshold = 0.2, Recall score = 0.9703\n",
            "Threshold = 0.3, Recall score = 0.9703\n",
            "Threshold = 0.4, Recall score = 0.9604\n",
            "Threshold = 0.5, Recall score = 0.9505\n",
            "Threshold = 0.6, Recall score = 0.9406\n",
            "Threshold = 0.7, Recall score = 0.9208\n",
            "Threshold = 0.8, Recall score = 0.9208\n",
            "Threshold = 0.9, Recall score = 0.9010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAALMCAYAAAD5OkRgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJUsaALEmSJGX+P7obpnLv9mImAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plqEdje0wlcS",
        "colab_type": "text"
      },
      "source": [
        "## Useful reference:\n",
        "URL_1 = \"https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d\" **GBM**\n",
        "\n",
        "URL_2 = \"https://github.com/groverpr/Machine-Learning/blob/master/notebooks/01_Gradient_Boosting_Scratch.ipynb\" **GBM code from scratch to complete**"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Details of importing dataset from Kaggle and organizing train/validation/ files_honey-bee-pollen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xslittlemaggie/Deep-Learning-Machine-Learning-Projects/blob/master/Details_of_importing_dataset_from_Kaggle_and_organizing_train_validation_files_honey_bee_pollen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pnicbrDVyBD",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8rkbnKbV0Lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d90d5c15-5818-4c28-d41f-9574a7654373"
      },
      "source": [
        "# libraries for files\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "# libraries for image processing and NN models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from keras.optimizers import SGD, adam, RMSprop"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBSEIl7_V7eO",
        "colab_type": "text"
      },
      "source": [
        "## Step 1. Load data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8efLS_6AFA5M",
        "colab_type": "text"
      },
      "source": [
        "#### 1. get Kaggle API and key  (please enter your kaggle user name and key)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ295XPaV9C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"maggie\" # username from the json file \n",
        "os.environ['KAGGLE_KEY'] = \"7adfc6c4e6c5eec087031fbb7397aee5\" # key from the json file (This key is incorrect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEImSbalV_XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeT4rR45FKt4",
        "colab_type": "text"
      },
      "source": [
        "#### 2. find the related dataset list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8nu1A5nWDfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "63e0fc65-f0c3-420a-8630-bffc16095549"
      },
      "source": [
        "!kaggle datasets list -s honey-bee-pollen  # It will list the 20 datasets including \"dogs-vs-cats\" from kaggle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                          title                                size  lastUpdated          downloadCount  \n",
            "-------------------------------------------  -----------------------------------  ----  -------------------  -------------  \n",
            "ivanfel/honey-bee-pollen                     Honey Bee pollen                     10MB  2018-11-20 16:06:11           1145  \n",
            "jenny18/open-source-bee-hive-labeled-images  Open Source Bee Hive Labeled Images  31MB  2018-09-08 01:06:10            156  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTD03K9yFOa7",
        "colab_type": "text"
      },
      "source": [
        "#### 3. download dataset   \n",
        "**ivanfel/honey-bee-pollen**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZiuan5EsRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "eb355a7d-f598-4a66-b8ea-18c9ac6f19c3"
      },
      "source": [
        "!kaggle datasets download -d ivanfel/honey-bee-pollen -p /content/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading honey-bee-pollen.zip to /content\n",
            " 50% 5.00M/9.98M [00:00<00:00, 24.8MB/s]\n",
            "100% 9.98M/9.98M [00:00<00:00, 39.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WHHscAdFbjQ",
        "colab_type": "text"
      },
      "source": [
        "#### 4. check the datafile name from left at Files\n",
        "\n",
        "The file name is home-bee-pollen.zip, so we need to unzip this file and check how the data inside look like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt7iM4qXWIyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/honey-bee-pollen.zip -d /content/honey-bee-pollen/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjpQf9B5F4go",
        "colab_type": "text"
      },
      "source": [
        "#### 4. create train/validation files to store training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akWww3KNEmuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train/validation files\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/train\")\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/validation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El9GH3VXGSGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create subfiles NP/P files under train and validation files respectively\n",
        "\n",
        "# 1. create subfile NP and P files under train dataset\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/train/NP\")\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/train/P\")\n",
        "\n",
        "# 2. create subfile NP and P files under validation dataset\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/validation/NP\")\n",
        "os.mkdir(\"/content/honey-bee-pollen/PollenDataset/images/validation/P\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNoB70rGyBm",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Move all images beginning with NP to NP file under train, move all images beginning with P to P file under train. \n",
        "\n",
        "Later we can randomly move 10% of images from NP under train to NP under validation, and 10% images from P under train to P under validation. \n",
        "\n",
        "You can use other methods to do this split. \n",
        "\n",
        "\n",
        "It seems that this is no images for testing from this dataset.I didn't see any images unlabelled. Maybe I missed some information, please check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQqXu6peGeOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "02549435-9b59-4439-88e6-37b8de86ab12"
      },
      "source": [
        "# check for one image about how the image file look like\n",
        "pathes = glob.glob('/content/honey-bee-pollen/PollenDataset/images/*.jpg')\n",
        "for path in pathes:\n",
        "  head, tail = os.path.split(path)\n",
        "  print(\"head:\", head)\n",
        "  print(\"tail:\", tail)\n",
        "  break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: /content/honey-bee-pollen/PollenDataset/images\n",
            "tail: P53827-50r.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1xNQwlPIAU8",
        "colab_type": "text"
      },
      "source": [
        "From the output above, the tail path of the image includes the labelling information, P or NP. \n",
        "\n",
        "Later, I will check the first letter of the image, if it is N (move to NP file), or P (move to P file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0icSh8QH5ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move all images beginning with NP to NP file under train, all images beginning with P to P file under train\n",
        "pathes = glob.glob('/content/honey-bee-pollen/PollenDataset/images/*.jpg')\n",
        "for path in pathes:\n",
        "  head, tail = os.path.split(path)\n",
        "  if tail[:1] == 'N':\n",
        "    new_path = \"/content/honey-bee-pollen/PollenDataset/images/train/NP/\" + tail\n",
        "  elif tail[:1] == 'P':\n",
        "    new_path = \"/content/honey-bee-pollen/PollenDataset/images/train/P/\" + tail\n",
        "  os.rename(path, new_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18TfLH2QJwhE",
        "colab_type": "text"
      },
      "source": [
        "If you run the code line by line. Now you can go to the file,  you can see that we have moved all images to NP file and P files based on the image file names under train dataset.\n",
        "\n",
        "Next we want to randomly move 10% of the images from NP (under train dataset) to NP file, \n",
        "and 10% of the images from P (under train dataset) to P file under validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuMWcwCVK8Xo",
        "colab_type": "text"
      },
      "source": [
        "#### 6. check the number of images in NP and P files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIzpML-MLAPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e81ea107-566f-4b2c-b10c-cff7ff131f31"
      },
      "source": [
        "total_NP_iamges = os.listdir(\"/content/honey-bee-pollen/PollenDataset/images/train/NP\")\n",
        "print(\"The total number of images labelled NP is: \", len(total_NP_iamges))\n",
        "\n",
        "total_P_iamges = os.listdir(\"/content/honey-bee-pollen/PollenDataset/images/train/P\")\n",
        "print(\"The total number of images labelled P is: \", len(total_P_iamges))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total number of images labelled NP is:  345\n",
            "The total number of images labelled P is:  369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yKDzqwELfUw",
        "colab_type": "text"
      },
      "source": [
        "#### 7. move 10% of images to validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1h_9i98HpUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NP in validation data\n",
        "NP_pathes = glob.glob('/content/honey-bee-pollen/PollenDataset/images/train/NP/*.jpg') \n",
        "val_NP_idx = random.sample((range(len(total_NP_iamges))), k = 100)  # any number you want to move\n",
        "val_NP = [NP_pathes[idx] for idx in val_NP_idx]\n",
        "\n",
        "for path in val_NP:\n",
        "  head, tail = os.path.split(path)  \n",
        "  new_path = \"/content/honey-bee-pollen/PollenDataset/images/validation/NP/\" + tail \n",
        "  os.rename(path, new_path)  \n",
        "  \n",
        "# P in validation data\n",
        "P_pathes = glob.glob('/content/honey-bee-pollen/PollenDataset/images/train/P/*.jpg') \n",
        "val_P_idx = random.sample((range(len(total_P_iamges))), k = 100)  # any number you want to move\n",
        "val_P = [P_pathes[idx] for idx in val_P_idx]\n",
        "\n",
        "for path in val_P:\n",
        "  head, tail = os.path.split(path)  \n",
        "  new_path = \"/content/honey-bee-pollen/PollenDataset/images/validation/P/\" + tail \n",
        "  os.rename(path, new_path) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wqLY63oNYoG",
        "colab_type": "text"
      },
      "source": [
        "Now we have successfully moved the images to **train/NP** and **train/P** files, and **validation/NP** and **validation/P** files.\n",
        "\n",
        "You can check the results from the left files"
      ]
    }
  ]
}